# ScraperBackendService> **[English](README.en.md) | 中文**HanimetaScraper 的核心后端服务，为 Hanime 和 DLsite 内容提供 REST API，具备**高级速率限制和反检测功能**。## 功能特性### 核心能力- **多提供商支持** - Hanime、DLsite，统一接口- **RESTful API** - 标准化 JSON 响应- **反机器人保护** - Playwright 浏览器自动化与隐身模式- **智能缓存** - 内存缓存配合 LRU 淘汰策略，减少重复请求- **身份验证** - 可选 API Token 认证，用于安全部署### 高级速率限制- **并发控制** - 可配置的提供商访问限制（默认：3个槽位）- **每槽速率限制** - 强制连续请求的最小间隔（默认：30秒）- **请求队列** - 最多等待15秒获取可用槽位，而非立即拒绝- **智能节流** - 防止IP封禁的同时最大化吞吐量### 性能优化- **激进内存管理** - 可选的GC优化，适用于低内存环境- **扩展超时** - 150秒后端超时 + 180秒前端超时，确保完整请求流程- **缓存统计** - 监控缓存命中率和性能指标- **结构化日志** - 多级详细度，用于调试和监控## API 端点### 基础端点- `GET /` - 服务信息和认证状态- `GET /health` - 健康检查端点- `GET /cache/stats` - 缓存统计（命中率、驱逐次数等）- `DELETE /cache/clear` - 清空所有缓存条目- `DELETE /cache/{provider}/{id}` - 删除特定缓存条目### Hanime 端点- `GET /api/hanime/search?title={query}&max={limit}` - 按标题搜索（速率限制）- `GET /api/hanime/{id}` - 按ID获取详情（速率限制）### DLsite 端点- `GET /api/dlsite/search?title={query}&max={limit}` - 按标题搜索（速率限制）- `GET /api/dlsite/{id}` - 按ID获取详情（速率限制）### 工具端点- `GET /r/dlsite/{id}` - 重定向到DLsite产品页面## 配置### 主要配置项（appsettings.json）```json{  "ServiceConfig": {    "Port": 8585,    "Host": "0.0.0.0",    "AuthToken": "",    "TokenHeaderName": "X-API-Token",    "HanimeMaxConcurrentRequests": 3,    "DlsiteMaxConcurrentRequests": 3,    "HanimeRateLimitSeconds": 30,    "DlsiteRateLimitSeconds": 30,    "RequestTimeoutSeconds": 150,    "EnableAggressiveMemoryOptimization": true  }}```### 配置选项详解| 配置项 | 描述 | 默认值 | 推荐范围 ||--------|------|--------|----------|| **Port** | HTTP 监听端口 | 8585 | 1024-65535 || **Host** | 监听地址 | "0.0.0.0" | "127.0.0.1"（本地）/"0.0.0.0"（所有接口） || **AuthToken** | API 认证令牌 | 空字符串 | 强随机字符串（生产环境必须） || **TokenHeaderName** | 认证头名称 | "X-API-Token" | 自定义头名称 || **HanimeMaxConcurrentRequests** | Hanime 并发槽位 | 3 | 1-10 || **DlsiteMaxConcurrentRequests** | DLsite 并发槽位 | 3 | 1-10 || **HanimeRateLimitSeconds** | Hanime 每槽速率限制 | 30 | 10-60 || **DlsiteRateLimitSeconds** | DLsite 每槽速率限制 | 30 | 10-60 || **RequestTimeoutSeconds** | 请求超时时间（秒） | 150 | 90-300 || **EnableAggressiveMemoryOptimization** | 启用激进GC | true | true/false |### 并发控制说明**提供商并发限制** - 统一控制对提供商网站的访问：- `HanimeMaxConcurrentRequests` - 限制对 Hanime 网站的同时访问数- `DlsiteMaxConcurrentRequests` - 限制对 DLsite 网站的同时访问数- 包括所有操作：搜索请求、详情获取、直接ID查询- 达到限制时，请求等待最多15秒以获取可用槽位- 15秒后仍无可用槽位则返回429状态，前端将自动重试### 速率限制说明**每槽独立速率限制** - 为每个并发槽提供独立的速率控制：- `HanimeRateLimitSeconds` - 每个 Hanime 槽在缓存未命中时的最小请求间隔- `DlsiteRateLimitSeconds` - 每个 DLsite 槽在缓存未命中时的最小请求间隔- 缓存命中时绕过速率限制，立即返回- 设置为 0 可禁用速率限制- 每个槽有独立计时器，不同槽之间互不干扰**速率限制工作流程：**1. 请求到达 → 检查缓存2. 缓存命中 → 立即返回（无速率限制）✅3. 缓存未命中 → 获取并发槽4. 槽获取成功 → 检查槽的最后请求时间5. 如需等待 → 等待直到满足速率限制间隔6. 从提供商获取 → 缓存并返回### 环境变量覆盖以下环境变量可覆盖配置文件设置：| 环境变量 | 对应配置 | 示例 ||----------|----------|------|| **SCRAPER_PORT** | Port | `8080` || **SCRAPER_AUTH_TOKEN** | AuthToken | `your-secret-token-here` |### 缓存配置缓存系统自动配置，主要参数：- **缓存容量**：100个条目- **成功结果TTL**：2分钟- **失败结果TTL**：2分钟- **驱逐策略**：LRU（最近最少使用）**提示：** 提高缓存命中率可显著提升响应速度，因为缓存命中时完全绕过速率限制。### 性能调优建议**低负载环境（个人使用）：**```json{  "HanimeMaxConcurrentRequests": 3,  "DlsiteMaxConcurrentRequests": 3,  "HanimeRateLimitSeconds": 20,  "DlsiteRateLimitSeconds": 20}```**高负载环境（多用户）：**```json{  "HanimeMaxConcurrentRequests": 10,  "DlsiteMaxConcurrentRequests": 10,  "HanimeRateLimitSeconds": 20,  "DlsiteRateLimitSeconds": 20}```**保守设置（避免封禁）：**```json{  "HanimeMaxConcurrentRequests": 1,  "DlsiteMaxConcurrentRequests": 1,  "HanimeRateLimitSeconds": 60,  "DlsiteRateLimitSeconds": 60}```**禁用速率限制（仅依赖并发控制）：**```json{  "HanimeMaxConcurrentRequests": 3,  "DlsiteMaxConcurrentRequests": 3,  "HanimeRateLimitSeconds": 0,  "DlsiteRateLimitSeconds": 0}```### 超时配置建议**RequestTimeoutSeconds 计算公式：**```RequestTimeoutSeconds >= 槽等待时间(15s) + 速率限制时间(30s) + 刮削时间(60s) + 缓冲时间(45s)推荐值：150秒```## 部署### 开发环境```bashcd ScraperBackendServicedotnet run```### 生产环境```bashcd ScraperBackendServicedotnet publish -c Release -o ./publishcd publishdotnet ScraperBackendService.dll```### Docker```bashdocker build -t hanimeta-scraper-backend .docker run -p 8585:8585 hanimeta-scraper-backend```## 监控和诊断### 健康检查```bashcurl http://localhost:8585/health```### 缓存统计```bashcurl http://localhost:8585/cache/stats```### 清空缓存```bashcurl -X DELETE http://localhost:8585/cache/clear```## 故障排除### 常见问题**503 Service Unavailable**- 检查并发槽位配置- 增加 `MaxConcurrentRequests` 值**请求超时**- 增加 `RequestTimeoutSeconds` 值- 检查网络连接稳定性**频繁429错误**- 减少 `RateLimitSeconds` 值- 增加并发槽位数**内存使用过高**- 启用 `EnableAggressiveMemoryOptimization`- 减小缓存大小### 日志级别在 `appsettings.json` 中调整日志级别：```json{  "Logging": {    "LogLevel": {      "Default": "Information",      "ScraperBackendService": "Debug"    }  }}```## 技术栈- **.NET 8** - 现代C#运行时，性能改进- **ASP.NET Core** - Web API框架，依赖注入- **Playwright** - 无头浏览器自动化，动态内容处理- **HtmlAgilityPack** - 快速HTML解析和DOM导航- **System.Text.Json** - 高性能JSON序列化## 安全注意事项### 生产部署1. **设置强认证令牌**：`AuthToken` 必须是强随机字符串2. **限制网络访问**：使用防火墙限制访问IP3. **使用HTTPS**：配置反向代理（如Nginx）提供HTTPS4. **监控日志**：定期检查异常访问模式### 示例Nginx配置```nginxserver {    listen 443 ssl;    server_name your-domain.com;        ssl_certificate /path/to/cert.pem;    ssl_certificate_key /path/to/key.pem;        location / {        proxy_pass http://127.0.0.1:8585;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        proxy_set_header X-Forwarded-Proto $scheme;    }}```---**HanimetaScraper 后端服务** - 为 Jellyfin 元数据刮削提供可靠的API服务 🚀