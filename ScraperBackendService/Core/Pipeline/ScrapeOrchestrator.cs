using Microsoft.Extensions.Logging;using ScraperBackendService.Core.Abstractions;using ScraperBackendService.Core.Normalize;using ScraperBackendService.Core.Util;using ScraperBackendService.Models;namespace ScraperBackendService.Core.Routing;/// <summary>/// Unified scrape orchestrator for coordinating content retrieval operations./// Manages different scraping strategies based on input type and route configuration./// Handles search-to-detail workflows with concurrent processing and result ordering./// </summary>/// <remarks>/// This orchestrator:/// - Determines scraping strategy based on ScrapeRoute configuration/// - Manages concurrent detail fetching with configurable parallelism/// - Maintains result ordering during parallel operations/// - Provides unified interface for different content identification methods/// - Handles keyword normalization and filename-based extraction/// </remarks>/// <example>/// Usage example:/// var orchestrator = new ScrapeOrchestrator(provider, networkClient, logger);/// /// // Direct ID lookup/// var results1 = await orchestrator.FetchAsync("RJ123456", ScrapeRoute.ById, 1, ct);/// /// // Search-based retrieval/// var results2 = await orchestrator.FetchAsync("anime title", ScrapeRoute.Auto, 10, ct);/// /// // Filename-based extraction/// var results3 = await orchestrator.FetchAsync("Movie [RJ123456].mp4", ScrapeRoute.ByFilename, 5, ct);/// </example>public sealed class ScrapeOrchestrator{    private readonly IMediaProvider _provider;    private readonly INetworkClient _net;    private readonly ILogger _log;    /// <summary>    /// Initializes a new instance of the ScrapeOrchestrator.    /// </summary>    /// <param name="provider">Media provider for content operations</param>    /// <param name="net">Network client for HTTP operations</param>    /// <param name="log">Logger for operation tracking</param>    public ScrapeOrchestrator(IMediaProvider provider, INetworkClient net, ILogger log)    {        _provider = provider;        _net = net;        _log = log;    }    /// <summary>    /// Fetches content metadata using the specified scraping strategy.    /// Coordinates the entire scraping workflow from input processing to result compilation.    /// </summary>    /// <param name="input">Input string (ID, filename, or search term)</param>    /// <param name="route">Scraping strategy to use</param>    /// <param name="maxResults">Maximum number of results to return</param>    /// <param name="ct">Cancellation token</param>    /// <returns>List of metadata objects for matching content</returns>    /// <remarks>    /// Route behavior:    /// - ById: Direct ID-based lookup, expects valid provider ID    /// - ByFilename: Extracts keywords from filename for search    /// - Auto: Uses search-based strategy for all inputs (recommended)    /// </remarks>    /// <example>    /// // Direct ID lookup (fastest, single result)    /// var directResult = await orchestrator.FetchAsync("RJ123456", ScrapeRoute.ById, 1, ct);    ///     /// // Filename-based search (extracts keywords from filename)    /// var filenameResults = await orchestrator.FetchAsync("Movie.Title.2024.RJ123456.mp4", ScrapeRoute.ByFilename, 5, ct);    ///     /// // Auto search (handles any input type)    /// var searchResults = await orchestrator.FetchAsync("romance anime", ScrapeRoute.Auto, 10, ct);    /// </example>    public async Task<List<Metadata>> FetchAsync(        string input,        ScrapeRoute route,        int maxResults,        CancellationToken ct)    {        switch (route)        {            case ScrapeRoute.ById:                if (!_provider.TryParseId(input, out var id))                    throw new ArgumentException($"ID parsing failed: {input}");                return await FetchByIdAsync(id, ct);            case ScrapeRoute.ByFilename:                return await SearchAndFetchAsync(input, maxResults, ct);            case ScrapeRoute.Auto:            default:                // Auto mode now always uses search instead of intelligent ID detection                // This ensures that title search remains title search even if the input looks like an ID                return await SearchAndFetchAsync(input, maxResults, ct);        }    }    /// <summary>    /// Performs direct ID-based content lookup for known identifiers.    /// Constructs detail URL from ID and fetches metadata directly.    /// </summary>    /// <param name="id">Validated provider-specific content ID</param>    /// <param name="ct">Cancellation token</param>    /// <returns>List containing single metadata result or empty list if not found</returns>    private async Task<List<Metadata>> FetchByIdAsync(string id, CancellationToken ct)    {        var url = _provider.BuildDetailUrlById(id);        var meta = await _provider.FetchDetailAsync(url, ct);        return (meta is null) ? new() : new() { meta };    }    /// <summary>    /// Performs search-based content retrieval with concurrent detail fetching.    /// Normalizes input keywords, executes search, and fetches detailed metadata in parallel.    /// </summary>    /// <param name="filenameOrText">Filename or search text to process</param>    /// <param name="maxResults">Maximum number of results to return</param>    /// <param name="ct">Cancellation token</param>    /// <returns>List of metadata objects with complete information</returns>    /// <remarks>    /// This method:    /// 1. Normalizes keywords from filename or search text    /// 2. Executes provider search with normalized keywords    /// 3. Fetches detailed metadata concurrently (degree=4)    /// 4. Maintains result ordering during parallel processing    /// 5. Fills missing metadata fields from search results    /// </remarks>    private async Task<List<Metadata>> SearchAndFetchAsync(        string filenameOrText, int maxResults, CancellationToken ct)    {        var kw = TextNormalizer.BuildQueryFromFilename(filenameOrText);        if (string.IsNullOrWhiteSpace(kw))            kw = filenameOrText?.Trim() ?? "";        var hits = await _provider.SearchAsync(kw, maxResults, ct);        var results = await OrderedAsync.ForEachAsync(hits.ToList(), degree: 4, async h =>        {            var m = await _provider.FetchDetailAsync(h.DetailUrl, ct);            if (m == null) return null;            // Use search results to fill missing fields            if (string.IsNullOrWhiteSpace(m.Title) && !string.IsNullOrWhiteSpace(h.Title))                m.Title = h.Title;            if (string.IsNullOrWhiteSpace(m.Primary) && !string.IsNullOrWhiteSpace(h.CoverUrl))                m.Primary = h.CoverUrl;            return m;        });        return results.Where(m => m != null).ToList()!;    }}