# HanimetaScraper> **[‰∏≠Êñá](README.md) | English**A .NET 8 based Jellyfin metadata scraping solution for Hanime and DLsite content with **advanced Playwright-powered anti-detection** and rate limiting capabilities.## üöÄ Quick Start### üì¶ Pre-built Release Package (Recommended for Most Users)The easiest way to get started is using our pre-built release packages:#### For Windows Users1. **Download the latest release** from [GitHub Releases](https://github.com/Qing-98/HanimetaScraper/releases)2. **Extract the backend service**:   - Download `ScraperBackendService-x.x.x.zip`   - Extract to your desired location (e.g., `C:\HanimetaScraper\`)3. **Set up Playwright browsers** (first-time only):   ```batch   # Navigate to the extracted directory   cd backend   install-playwright.bat   ```4. **Start the backend service**:   ```batch   start-backend.bat   ```5. **Install Jellyfin plugins**:   - Download `Jellyfin.Plugin.Hanimeta.DLsiteScraper.zip` and `Jellyfin.Plugin.Hanimeta.HanimeScraper.zip`   - Stop Jellyfin service   - Extract plugin files to `C:\ProgramData\Jellyfin\Server\plugins\`   - Restart Jellyfin service6. **Configure plugins** in Jellyfin Admin Dashboard ‚Üí Plugins#### For Linux/macOS Users1. **Download the latest release** from [GitHub Releases](https://github.com/Qing-98/HanimetaScraper/releases)2. **Extract the backend service**:   ```bash   unzip ScraperBackendService-x.x.x.zip   cd backend   ```3. **Set up Playwright browsers** (first-time only):   ```bash   chmod +x install-playwright.sh   ./install-playwright.sh   ```4. **Start the backend service**:   ```bash   chmod +x start-backend.sh   ./start-backend.sh   ```5. **Install Jellyfin plugins**:   ```bash   # Stop Jellyfin service   sudo systemctl stop jellyfin      # Extract plugins to Jellyfin directory   unzip Jellyfin.Plugin.Hanimeta.DLsiteScraper.zip -d /var/lib/jellyfin/plugins/Jellyfin.Plugin.Hanimeta.DLsiteScraper/   unzip Jellyfin.Plugin.Hanimeta.HanimeScraper.zip -d /var/lib/jellyfin/plugins/Jellyfin.Plugin.Hanimeta.HanimeScraper/      # Restart Jellyfin service   sudo systemctl start jellyfin   ```6. **Configure plugins** in Jellyfin Admin Dashboard ‚Üí Plugins#### Plugin Configuration (All Platforms)After installing the plugins, configure them in Jellyfin:1. Open Jellyfin Admin Dashboard2. Navigate to **Dashboard ‚Üí Plugins**3. Find "DLsite Scraper" and "Hanime Scraper" plugins4. Click **Settings** for each plugin and configure:   - **Backend URL**: `http://127.0.0.1:8585`   - **API Token**: (leave empty unless you set one in backend)   - **Enable Logging**: `false` (set `true` for debugging)   - **Tag Mapping Mode**: `Tags` or `Genres`### üõ†Ô∏è Build from Source (For Developers)#### Windows Users```batch# One-click installer wizard (Run as Administrator)# Automatically installs .NET 8 SDK and Playwright browsersscripts\install-wizard.bat# Or use PowerShell management script.\scripts\manage.ps1 build.\scripts\manage.ps1 setup-playwright    # Install Playwright browsers.\scripts\manage.ps1 start.\scripts\manage.ps1 install```üìã **[Complete Windows Guide](WINDOWS_README.md)** - Detailed instructions for Windows users#### Linux/macOS Users```bash# Quick setup script (includes Playwright setup)./scripts/quick-start.sh# Manual setupcd ScraperBackendServicedotnet run```## ‚ö†Ô∏è Important: Playwright RequirementsThis solution uses **Microsoft Playwright** for advanced anti-bot capabilities:- **Automatic browser installation** (~100MB Chromium download)- **System dependencies** (handled by installation scripts)- **First-time setup required** before running backend service**Quick Playwright Setup:**```powershell# Windows.\scripts\manage.ps1 setup-playwright# Linux/macOS./scripts/quick-start.sh setup-playwright```## Project Structure### Backend Service- **ScraperBackendService** - Core scraping backend service with **Playwright browser automation**### Jellyfin Plugins- **Jellyfin.Plugin.Hanimeta.HanimeScraper** - Hanime metadata provider plugin- **Jellyfin.Plugin.Hanimeta.DLsiteScraper** - DLsite metadata provider plugin- **Jellyfin.Plugin.Hanimeta.Common** - Shared plugin library### Test Tools- **NewScraperTest** - Backend service test suite## Features### Core Features- üîç **Smart Search** - Search content by title or ID- üìä **Rich Metadata** - Title, description, rating, release date, personnel information- üñºÔ∏è **Image Support** - Cover, backdrop, thumbnails- üéå **Multi-language** - Support for Chinese and Japanese content- ‚ö° **High Performance** - Concurrent processing, intelligent caching, retry mechanisms### Advanced Anti-Detection Features (Playwright-Powered)- üõ°Ô∏è **Advanced Anti-Detection** - Playwright-based browser automation with stealth profiles- üåê **Cloudflare Bypass** - Automatic challenge detection and resolution- üé≠ **Browser Fingerprint Randomization** - Dynamic user agent and viewport management- üîÑ **Session Management** - Persistent browser contexts for improved success rates- üö´ **Request Interception** - Smart resource blocking for enhanced performance### Performance & Reliability- ‚è±Ô∏è **Rate Limiting** - Per-slot rate limiting to prevent IP blocking- üîÑ **Request Queuing** - Wait for available slots instead of immediate failure- üíæ **Smart Caching** - Memory cache with LRU eviction policy- üìù **Structured Logging** - Comprehensive logging with multiple verbosity levels- ‚öôÔ∏è **Flexible Configuration** - Fine-grained control over concurrency and rate limits### Windows Integration- üñ•Ô∏è **One-Click Installer** - Automated setup wizard with .NET SDK and Playwright installation- üîß **PowerShell Management** - Advanced management script with Playwright setup- üéØ **Visual Studio Integration** - Complete VS Code and Visual Studio 2022 support- üìÅ **Desktop Shortcuts** - Easy access to backend service and management tools## Architecture```Jellyfin Plugins ‚Üí HTTP API (3min timeout) ‚Üí ScraperBackendService (150s timeout) ‚Üí Playwright Browser ‚Üí Website Scrapers                                                      ‚Üì                                    ‚Üì                                          Concurrency Control (3 slots)         Anti-Detection Features                                                      ‚Üì                                    ‚Üì                                          Rate Limiting (30s per slot)          Stealth Browser Profiles                                                      ‚Üì                                    ‚Üì                                          Provider Access (Hanime/DLsite)       Cloudflare Bypass```The backend service provides unified API with:- **Concurrency Control**: Limits simultaneous requests per provider- **Rate Limiting**: Enforces delay between requests from the same slot- **Smart Caching**: Reduces redundant requests- **Request Queuing**: Waits up to 15s for available slots- **Playwright Integration**: Advanced browser automation for anti-bot features## Installation### üì¶ Using Pre-built Release Packages (Recommended)This is the easiest installation method for most users:1. **Download Release Files**   - Visit [GitHub Releases](https://github.com/Qing-98/HanimetaScraper/releases)   - Download the latest release files:     - `ScraperBackendService-x.x.x.zip` - Backend service     - `Jellyfin.Plugin.Hanimeta.DLsiteScraper.zip` - DLsite plugin     - `Jellyfin.Plugin.Hanimeta.HanimeScraper.zip` - Hanime plugin2. **Backend Service Setup**   ```bash   # Extract backend service   unzip ScraperBackendService-x.x.x.zip   cd backend      # Install Playwright browsers (first-time only)   # Windows: run install-playwright.bat   # Linux/macOS: run ./install-playwright.sh      # Start the service   # Windows: run start-backend.bat   # Linux/macOS: run ./start-backend.sh   ```3. **Plugin Installation**   ```bash   # Stop Jellyfin   sudo systemctl stop jellyfin  # Linux   # Or stop Jellyfin service on Windows      # Extract plugins to Jellyfin plugins directory   # Linux: /var/lib/jellyfin/plugins/   # Windows: C:\ProgramData\Jellyfin\Server\plugins\   # macOS: ~/Library/Application Support/jellyfin/plugins/      unzip Jellyfin.Plugin.Hanimeta.DLsiteScraper.zip -d [JELLYFIN_PLUGINS_DIR]/Jellyfin.Plugin.Hanimeta.DLsiteScraper/   unzip Jellyfin.Plugin.Hanimeta.HanimeScraper.zip -d [JELLYFIN_PLUGINS_DIR]/Jellyfin.Plugin.Hanimeta.HanimeScraper/      # Restart Jellyfin   sudo systemctl start jellyfin  # Linux   ```4. **Configure Plugins**   - Open Jellyfin Admin Dashboard   - Go to Dashboard ‚Üí Plugins   - Configure each scraper plugin:     - Backend URL: `http://127.0.0.1:8585`     - API Token: (leave empty unless set in backend)     - Enable Logging: `false` (true for debugging)### üõ†Ô∏è Build from Source#### üñ•Ô∏è Windows (Recommended Path)##### Option 1: One-Click Installer (Includes Playwright Setup)1. Download the latest release2. Right-click `scripts\install-wizard.bat` and "Run as administrator"3. Follow the interactive setup wizard (automatically installs .NET 8 SDK and Playwright)##### Option 2: PowerShell Management```powershell# Check status and get help.\scripts\manage.ps1 help.\scripts\manage.ps1 status# Full setup including Playwright.\scripts\manage.ps1 build           # Builds solution and sets up Playwright.\scripts\manage.ps1 setup-playwright # Manual Playwright setup.\scripts\manage.ps1 start           # Start backend service.\scripts\manage.ps1 install         # Install Jellyfin plugins```#### üêß Linux/macOS##### Automated Setup (Includes Playwright)```bash# Full setup with Playwright in one command./scripts/quick-start.sh# Or step by step./scripts/quick-start.sh build       # Includes Playwright setup./scripts/quick-start.sh start./scripts/quick-start.sh install```##### Manual Setup1. **Install .NET 8 SDK and Playwright**```bash# Install .NET 8sudo apt install dotnet-sdk-8.0  # Ubuntu/Debian# or download from Microsoft# Install Playwrightdotnet tool install --global Microsoft.Playwright.CLIplaywright install chromium --with-deps```2. **Backend Service Setup**```bashcd ScraperBackendServicedotnet run```3. **Plugin Installation**```bash# Copy plugin DLLs to Jellyfin plugins directory# Linux: /var/lib/jellyfin/plugins/# macOS: ~/Library/Application Support/jellyfin/plugins/```### Plugin Configuration1. Open Jellyfin Admin Dashboard2. Navigate to **Dashboard ‚Üí Plugins**3. Find installed scrapers and click **Settings**#### Configuration Options- **Backend URL**: ScraperBackendService URL | `http://127.0.0.1:8585` | `https://scraper.mydomain.com`- **API Token**: Backend service auth token (optional) | Empty | `your-secret-token-123`- **Enable Logging**: Plugin debug logging control | `false` | `true` (for debugging)- **Tag Mapping Mode**: Tag destination selection | `Tags` | `Tags` or `Genres`## Configuration### Backend Service ConfigurationMain configuration items (appsettings.json):```json{  "ServiceConfig": {    "Port": 8585,    "Host": "0.0.0.0",    "AuthToken": "",    "HanimeMaxConcurrentRequests": 3,    "DlsiteMaxConcurrentRequests": 3,    "HanimeRateLimitSeconds": 30,    "DlsiteRateLimitSeconds": 30,    "RequestTimeoutSeconds": 150  }}```**Configuration Explained:**| Setting | Description | Default | Recommended Range ||---------|-------------|---------|-------------------|| **Port** | HTTP listening port | 8585 | 1024-65535 || **Host** | Listening address | "0.0.0.0" | "127.0.0.1" (local) / "0.0.0.0" (all) || **AuthToken** | API authentication token | Empty | Strong random string || **HanimeMaxConcurrentRequests** | Hanime concurrent slots | 3 | 1-10 || **DlsiteMaxConcurrentRequests** | DLsite concurrent slots | 3 | 1-10 || **HanimeRateLimitSeconds** | Hanime rate limit (per slot) | 20 | 10-60 || **DlsiteRateLimitSeconds** | DLsite rate limit (per slot) | 20 | 10-60 || **RequestTimeoutSeconds** | Request timeout | 150 | 90-300 |**Playwright Performance Impact:**- **Memory**: Additional ~50-100MB per browser instance- **Startup Time**: +2-5 seconds for first request- **CPU**: Moderate during active scraping, low when idle**Rate Limiting Explained:**- **Concurrent Slots**: Limits how many requests can execute simultaneously- **Rate Limit**: Enforces minimum delay between consecutive requests from the same slot- **Request Queuing**: Requests wait up to 15s for available slots before returning 429**Example Scenarios:**| Scenario | Slots | Rate Limit | Behavior ||----------|-------|------------|----------|| **Aggressive** | 10 | 10s | Fast but risky (may trigger blocking) || **Balanced** | 3 | 30s | Good balance (recommended) || **Conservative** | 1 | 60s | Slowest but safest |### Plugin Configuration OptionsEach plugin supports the following configuration items:| Setting | Description | Default | Example ||---------|-------------|---------|---------| | **Backend URL** | ScraperBackendService URL | `http://127.0.0.1:8585` | `https://scraper.mydomain.com` || **API Token** | Backend service auth token (optional) | Empty | `your-secret-token-123` || **Enable Logging** | Plugin debug logging control | `false` | `true` (for debugging) || **Tag Mapping Mode** | Tag destination selection | `Tags` | `Tags` or `Genres` |**Tag Mapping Mode Explanation:**- **Tags Mode**: Series + Content Tags ‚Üí Jellyfin Tags field, Backend Genres ‚Üí Jellyfin Genres field- **Genres Mode**: Series + Content Tags ‚Üí Jellyfin Genres field (merged with Backend Genres)Configuration Path: **Admin Dashboard ‚Üí Plugins ‚Üí [Plugin Name] ‚Üí Settings**## Performance Tuning### Response Time Optimization**Best Case** (Cache Hit):```Request ‚Üí Cache Hit ‚Üí ResponseDuration: ~1ms ‚úÖ```**Normal Case** (Playwright + Rate Limited):```Request ‚Üí Wait for Slot ‚Üí Rate Limit Wait ‚Üí Playwright Browser ‚Üí Scrape ‚Üí Cache ‚Üí ResponseDuration: ~40-65s ‚è±Ô∏è (includes browser startup)```**Worst Case** (All Waits + Browser):```Request ‚Üí Wait 15s for Slot ‚Üí Rate Limit 30s ‚Üí Browser Startup 5s ‚Üí Scrape 60s ‚Üí ResponseDuration: ~110s üêå```### Configuration Recommendations**Personal Use** (Low traffic):```json{  "HanimeMaxConcurrentRequests": 3,  "HanimeRateLimitSeconds": 20}```**Multi-User** (High traffic):```json{  "HanimeMaxConcurrentRequests": 5,  "HanimeRateLimitSeconds": 30}```**Conservative** (Avoid blocking):```json{  "HanimeMaxConcurrentRequests": 1,  "HanimeRateLimitSeconds": 60}```### Disable Rate Limiting (Not Recommended)To disable rate limiting (for testing or private instances):```json{  "HanimeRateLimitSeconds": 0,  "DlsiteRateLimitSeconds": 0}```‚ö†Ô∏è **Warning**: Disabling rate limiting may result in IP blocking by target websites.## Management and Monitoring### Windows Management```powershell# Service management.\scripts\manage.ps1 start       # Start backend service.\scripts\manage.ps1 stop        # Stop backend service.\scripts\manage.ps1 status      # Check service status (includes Playwright)# Playwright management.\scripts\manage.ps1 setup-playwright  # Install/update Playwright browsers# Plugin management.\scripts\manage.ps1 install     # Install Jellyfin plugins.\scripts\manage.ps1 uninstall   # Remove plugins# Development.\scripts\manage.ps1 build       # Build solution (includes Playwright check).\scripts\manage.ps1 test        # Run tests.\scripts\manage.ps1 logs        # View logs```### Cross-Platform Scripts```bash# Linux/macOS./scripts/quick-start.sh [command]# Available commands: all, build, start, install, config, examples, setup-playwright```## Logging SystemThe backend service provides structured logging with multiple verbosity levels:**Always Visible (LogAlways):**- User operations (search/query start)- Operation results (success/failure/result count)- Rate limit waits- Service status- **Playwright browser events****Information Level (LogInformation):**- Cache operations- Internal flow status- **Browser startup/shutdown****Debug Level (LogDebug):**- Slot allocation details- Memory management- Performance metrics- **Detailed Playwright operations****Log Output Example:**```12:34:56 [HanimeDetail] Query: '12345'12:34:57 [HanimeDetail] Starting Playwright browser...12:34:59 [HanimeDetail] Browser ready, navigating...12:35:01 [HanimeDetail] Waiting 25s (rate limit)12:35:26 [HanimeDetail] ‚úÖ Found```## API Endpoints### Base- `GET /` - Service information (includes Playwright status)- `GET /health` - Health check (includes browser health)- `GET /cache/stats` - Cache statistics- `DELETE /cache/clear` - Clear all cache- `DELETE /cache/{provider}/{id}` - Remove specific cache entry### Hanime- `GET /api/hanime/search?title={query}&max={limit}` - Search by title- `GET /api/hanime/{id}` - Get details by ID### DLsite  - `GET /api/dlsite/search?title={query}&max={limit}` - Search by title- `GET /api/dlsite/{id}` - Get details by ID## Troubleshooting### Playwright-Specific Issues#### Playwright Not Installed**Symptoms:** "Playwright executable not found" errors**Solutions:**```powershell# Windows.\scripts\manage.ps1 setup-playwright# Linux/macOSdotnet tool install --global Microsoft.Playwright.CLIplaywright install chromium --with-deps```#### Browser Launch Failed**Symptoms:** "Failed to launch browser" errors**Solutions:**1. Check available memory (requires ~100MB per browser)2. Verify system dependencies:   ```bash   # Linux   sudo apt update && sudo apt install -y libnss3 libatk1.0-0 libdrm2 libxcomposite1   ```3. Restart backend service#### Browser Process Hangs**Symptoms:** Requests timeout, browser processes remain**Solutions:**1. Restart backend service (automatically cleans up browsers)2. Manually kill browser processes:   ```bash   # Linux/macOS   pkill -f chromium      # Windows   taskkill /f /im chrome.exe   ```### High Response Time**Symptoms:** Requests take 60+ seconds**Solutions:**1. Check cache hit rate: `GET /cache/stats`2. Reduce rate limit: `HanimeRateLimitSeconds: 15`3. Increase concurrent slots: `HanimeMaxConcurrentRequests: 5`4. **Monitor browser startup time** (first request takes longer)### Frequent 429 Errors**Symptoms:** Many "Service busy" messages**Solutions:**1. Increase concurrent slots: `HanimeMaxConcurrentRequests: 5`2. Increase backend timeout: `RequestTimeoutSeconds: 180`### IP Blocking**Symptoms:** Requests fail with Cloudflare challenges**Solutions:**1. Increase rate limit: `HanimeRateLimitSeconds: 45`2. Reduce concurrent slots: `HanimeMaxConcurrentRequests: 2`3. **Verify Playwright is working**: Check browser startup logs### Windows-Specific Issues**PowerShell Execution Policy:**```powershellSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser```**Plugin Installation Fails:**```batch# Run as Administratorscripts\install-wizard.bat# Or manually copy files.\scripts\manage.ps1 install -Force```**Backend Service Won't Start:**```batch# Check .NET installationdotnet --version# Check Playwright setup.\scripts\manage.ps1 setup-playwright# Use installer wizard to fix everythingscripts\install-wizard.bat```## Development### Visual Studio Code (Windows/Linux/macOS)1. Open project folder in VS Code2. Install recommended extensions (automatic prompt)3. Press **F5** to start debugging4. Use **Ctrl+Shift+P** ‚Üí `Tasks: Run Task` for build operations### Visual Studio 2022 (Windows)1. Open `HanimetaScraper.sln`2. Set `ScraperBackendService` as startup project3. Press **F5** to start debugging### Command Line```bash# Restore dependenciesdotnet restore# Build solutiondotnet build# Set up Playwright (required for development)dotnet tool install --global Microsoft.Playwright.CLIplaywright install chromium# Run backend servicecd ScraperBackendServicedotnet run# Run testscd Test/NewScraperTestdotnet run```## System Requirements### Backend Service- **.NET 8 Runtime** or SDK- **Playwright Dependencies**:  - Chromium browser (~100MB, auto-installed)  - System libraries (Linux: libnss3, libatk1.0-0, etc.)- **4GB RAM minimum** (8GB recommended for high load + browsers)- **Internet connection** for content scraping and browser installation- **Linux/Windows/macOS** support### Jellyfin Plugins- **Jellyfin 10.10.7** or later- **Backend Service** running and accessible (with Playwright setup)- **Network connectivity** to backend service## Release and Deployment### Automated Release (GitHub Actions)```bash# Update version and create release.\scripts\update-version.sh 1.1.0  # Linux/macOS.\scripts\update-version.bat 1.1.0  # Windowsgit add .git commit -m "chore: bump version to v1.1.0"git tag v1.1.0git push origin main --tags```### Manual Package Creation```powershell# Windows (includes Playwright setup scripts).\scripts\manage.ps1 release -Version "1.1.0"# Linux/macOS  ./scripts/quick-start.sh package```## Documentation- **[Installation Guide](INSTALL.md)** - Detailed installation instructions- **[Windows Guide](WINDOWS_README.md)** - Windows-specific documentation- **[Contributing Guide](CONTRIBUTING.md)** - Development and contribution guidelines- **[Security Policy](SECURITY.md)** - Security guidelines and reporting- **[Backend README](ScraperBackendService/README.md)** - Backend service documentation## LicenseMIT License## ContributingContributions are welcome! Please read the [Contributing Guide](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.**Note for Contributors**: Ensure you have Playwright set up in your development environment:```bashdotnet tool install --global Microsoft.Playwright.CLIplaywright install chromium```## SupportFor issues and feature requests, please use the [GitHub Issues](https://github.com/Qing-98/HanimetaScraper/issues) page.For general questions and discussions, visit [GitHub Discussions](https://github.com/Qing-98/HanimetaScraper/discussions).## ‚ö†Ô∏è Important Notes### First-Time Setup1. **Playwright browsers must be installed** before first use2. **Allow browser downloads** through firewall (~100MB download)3. **Additional memory requirements** due to browser processes### Performance Considerations- Browser startup adds 2-5 seconds to first requests- Each browser instance uses ~50-100MB memory- Browser cache grows over time (~50-200MB)### Anti-Detection Features- Advanced fingerprint randomization- Automatic challenge detection and handling- Persistent browser sessions for improved success rates- Smart resource blocking for enhanced performance---**Made with ‚ù§Ô∏è for the Jellyfin community**  **Powered by Microsoft Playwright for advanced anti-detection** üé≠